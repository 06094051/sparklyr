% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sdf_interface.R
\name{sdf_sample}
\alias{sdf_sample}
\title{Randomly Sample Rows from a Spark DataFrame}
\usage{
sdf_sample(x, fraction = 1, replacement = TRUE, seed = NULL)
}
\arguments{
\item{x}{An object coercable to a Spark DataFrame.}

\item{fraction}{The fraction to sample.}

\item{replacement}{Boolean; sample with replacement?}

\item{seed}{An (optional) integer seed.}
}
\description{
Draw a random sample of rows (with or without replacement)
from a Spark DataFrame.
}
\section{Transforming Spark DataFrames}{


The family of functions prefixed with \code{sdf_} generally
access the Scala Spark DataFrame API directly, and return a
lower-level Spark DataFrame object (represented in \R as a
\code{sparkapi_jobj}). To bring these back to the \code{dplyr}
world (in order to use, for example, \code{mutate}), you need
to invoke \code{\link{sdf_register}()}. This gives the Spark
DataFrame a table name in the associated Spark SQL context, and
then returns a \code{tbl_spark} which you can then use with
the \code{dplyr} interface.
}
\seealso{
Other Spark DataFrame functions: \code{\link{sdf_partition}},
  \code{\link{sdf_sort}}
}

