% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dplyr_spark.R
\name{sdf_partition}
\alias{sdf_partition}
\title{Partition a Spark Dataframe}
\usage{
sdf_partition(x, ..., seed = sample(.Machine$integer.max, 1))
}
\arguments{
\item{x}{A \code{tbl_spark}.}

\item{...}{Named parameters, mapping table names to weights.}

\item{seed}{Random seed to use for randomly partitioning the dataset. Set
this if you want your partitioning to be reproducible on repeated runs.}
}
\value{
An \R \code{list} of \code{tbl_spark}s.
}
\description{
Partition a Spark DataFrame into multiple groups. This routine is useful
for splitting a DataFrame into, for example, training and test datasets.
}
\examples{
\dontrun{
# randomly partition data into a 'training' and 'test'
# dataset, with 60\% of the observations assigned to the
# 'training' dataset, and 40\% assigned to the 'test' dataset
data(diamonds, package = "ggplot2")
diamonds_tbl <- copy_to(sc, diamonds, "diamonds")
partitions <- diamonds_tbl \%>\%
  sdf_partition(training = 0.6, test = 0.4)
print(partitions)
}
}

