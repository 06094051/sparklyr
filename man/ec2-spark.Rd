% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ec2_spark.R
\name{ec2-spark}
\alias{ec2-spark}
\alias{spark_ec2_cluster}
\alias{spark_ec2_deploy}
\alias{spark_ec2_destroy}
\alias{spark_ec2_login}
\alias{spark_ec2_master}
\alias{spark_ec2_rstudio}
\alias{spark_ec2_start}
\alias{spark_ec2_stop}
\alias{spark_ec2_web}
\title{Install an EC2 Spark cluster}
\usage{
spark_ec2_cluster(access_key_id, secret_access_key, pem_file, version = NULL,
  hadoop_version = NULL, cluster_name = "spark",
  instance_type = "m3.medium", region = NULL)

spark_ec2_deploy(cluster_info, instance_count = 1, copy_dir = NULL)

spark_ec2_start(cluster_info, instance_count = 1)

spark_ec2_stop(cluster_info)

spark_ec2_destroy(cluster_info)

spark_ec2_login(cluster_info)

spark_ec2_master(cluster_info)

spark_ec2_rstudio(cluster_info)

spark_ec2_web(cluster_info)
}
\arguments{
\item{access_key_id}{EC2 access key id. Create a new access key from https://console.aws.amazon.com/iam/home?#security_credential}

\item{secret_access_key}{EC2 secret access key.}

\item{pem_file}{Identity file for ssh connections.}

\item{version}{The Spark version to use.}

\item{cluster_name}{Name used to identify cluster.}

\item{instance_type}{Type of EC2 instance. Tested with "m3.medium" and "c3.4xlarge".}

\item{region}{The EC2 region to host this cluster.}

\item{cluster_info}{A collection of parameters required to use the EC2 cluster, initialized with spark_ec2_cluster.}

\item{instance_count}{The total number of EC2 instances to be provisioned.}

\item{copy_dir}{Copies all the contents (recursevely) of the given path into the driver node durint spark_ec2_deploy}
}
\description{
This function will install and launch a new an EC2 cluster and download required client components.
Returns a cluster information list to enable further commands.

Starts a previously stopped Spark instance in EC2

Stops a running Spark instance in EC2

Deletes an Spark instance in EC2

Logins into Spark in EC2

Retrieves master location from EC2

Opens RStudio in EC2

Opens the Spark web interface in EC2
}

