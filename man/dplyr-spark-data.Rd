% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dplyr_spark_data.R
\name{dplyr-spark-data}
\alias{dplyr-spark-data}
\alias{load_csv}
\alias{save_csv}
\title{Loads a CSV file and provides a data source compatible with dplyr}
\usage{
load_csv(con, path, repartition = 0)

save_csv(x, path)
}
\arguments{
\item{con}{Connection to dplyr source}

\item{path}{The path to the CSV file. Needs to be accessible from the cluster. Supports: "hdfs://" or "s3n://"}

\item{repartition}{Total of partitions used to distribute table or 0 (default) to avoid partitioning}

\item{x}{A dplyr operation, for instance, `tbls(db, "flights")`}
}
\description{
Loads a CSV file and provides a data source compatible with dplyr

Saves a dplyr sources as a CSV file
}

