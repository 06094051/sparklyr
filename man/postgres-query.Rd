% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spark_dbi_result.R
\name{postgres-query}
\alias{postgres-query}
\title{Execute a SQL statement on a database connection}
\arguments{
\item{conn}{A \code{\linkS4class{DBIConnectionSpark}} created by \code{dbConnect}.}

\item{statement}{An SQL string to execture}

\item{params}{A list of query parameters to be substituted into
a parameterised query.}
}
\description{
To retrieve results a chunk at a time, use \code{dbSendQuery},
\code{dbFetch}, then \code{ClearResult}. Alternatively, if you want all the
results (and they'll fit in memory) use \code{dbGetQuery} which sends,
fetches and clears for you.
}
\examples{
library(DBI)
db <- dbConnect(splyr::DBISpark())
dbWriteTable(db, "usarrests", datasets::USArrests, temporary = TRUE)

# Run query to get results as dataframe
dbGetQuery(db, "SELECT * FROM glights LIMIT 1")

# Send query to pull requests in batches
res <- dbSendQuery(db, "SELECT * FROM usarrests")
dbFetch(res, n = 1)
dbHasCompleted(res)
dbClearResult(res)

dbRemoveTable(db, "flights")

dbDisconnect(db)
}

