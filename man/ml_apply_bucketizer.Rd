% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ml_feature_transformation.R
\name{ml_apply_bucketizer}
\alias{ml_apply_bucketizer}
\title{Feature Transformation -- Bucketizer}
\usage{
ml_apply_bucketizer(df, input.col, output.col, splits)
}
\arguments{
\item{df}{A Spark Dataset.}

\item{input.col}{The name of the input column(s).}

\item{output.col}{The name of the output column.}

\item{splits}{A numeric vector of cutpoints, indicating the bucket
boundaries.}
}
\description{
Similar to \R's \code{\link{cut}} function, this transforms a numeric column
into a discretized column, with breaks specified through the \code{splits}
parameter.
}
\seealso{
See \url{http://spark.apache.org/docs/latest/ml-features.html} for
  more information on the set of transformations available for DataFrame
  columns in Spark.

Other feature transformation routines: \code{\link{ml_apply_binarizer}},
  \code{\link{ml_apply_discrete_cosine_transform}},
  \code{\link{ml_apply_elementwise_product}},
  \code{\link{ml_apply_index_to_string}},
  \code{\link{ml_apply_quantile_discretizer}},
  \code{\link{ml_apply_sql_transformer}},
  \code{\link{ml_apply_string_indexer}},
  \code{\link{ml_apply_vector_assembler}}
}

