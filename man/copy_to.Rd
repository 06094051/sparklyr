% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dplyr_spark.R
\name{copy_to}
\alias{copy_to}
\alias{copy_to.spark_connection}
\title{Copy a local R dataframe to Spark and provide a data source compatible with dplyr}
\usage{
\method{copy_to}{spark_connection}(dest, df, name = deparse(substitute(df)),
  memory = TRUE, repartition = 0, overwrite = FALSE, local_file = NULL,
  ...)
}
\arguments{
\item{dest}{A Spark connection}

\item{df}{Local data frame to copy}

\item{name}{Name of the destination table}

\item{memory}{Cache table into memory for improved performance}

\item{repartition}{Total of partitions used to distribute table or 0 (default) to avoid partitioning}

\item{overwrite}{When TRUE, overwrites table with existing name}

\item{local_file}{When TRUE, uses a local file to copy the data frame, this is only available in local installs.}

\item{...}{Unused}
}
\description{
Copy a local R dataframe to Spark and provide a data source compatible with dplyr
}

