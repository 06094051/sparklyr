% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dplyr_spark.R
\name{copy_to}
\alias{copy_to}
\alias{copy_to.src_spark}
\title{Copy a local R dataframe to Spark and provide a data source compatible with dplyr}
\usage{
\method{copy_to}{src_spark}(dest, df, name = deparse(substitute(df)), ...,
  memory = TRUE, repartition = 0, overwrite = FALSE)
}
\arguments{
\item{dest}{dplyr database interface}

\item{df}{Local data frame to copy}

\item{name}{Name of the destination table}

\item{...}{Unused}

\item{memory}{Cache table into memory for improved performance}

\item{repartition}{Total of partitions used to distribute table or 0 (default) to avoid partitioning}

\item{overwrite}{When TRUE, overwrites table with existing name}
}
\description{
Copy a local R dataframe to Spark and provide a data source compatible with dplyr
}

