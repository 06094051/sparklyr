---
title: "RSpark ML: Examples"
output:
  github_document:
    fig_width: 9
    fig_height: 5
---

## Initialization

```{r}
library(rspark)
library(dplyr)
library(ggplot2)

sc <- spark_connect("local", cores = "auto", version = "2.0.0-preview")
db <- src_spark(sc)

copy_to(db, iris, "iris")
iris_tbl <- tbl(db, "iris")
```

## KMeans in R

```{r}
cl <- iris %>%
  select(Petal.Width, Petal.Length) %>%
  kmeans(centers = 3)

centers <- as.data.frame(cl$centers)

iris %>%
  select(Petal.Width, Petal.Length) %>%
  ggplot(aes(Petal.Length, Petal.Width)) +
    geom_point(data = centers, aes(Petal.Width, Petal.Length), size = 60, alpha = 0.1) +
    geom_point(data = iris, aes(Petal.Width, Petal.Length), size = 2, alpha = 0.5)
```

## KMeans in RSpark

Basing kmeans over Spark on [spark.mllib K-means](http://spark.apache.org/docs/latest/mllib-clustering.html#k-means)

Note that the names of variables within the iris `tbl` have been transformed
(replacing `.` with `_`) to work around an issue in the Spark 2.0.0-preview
used in constructing this document -- we expect the issue to be resolved with
the release of Spark 2.0.0.

```{r}
model <- tbl(db, "iris") %>%
  select(Petal_Width, Petal_Length) %>%
  ml_kmeans(centers = 3)

tbl(db, "iris") %>%
  select(Petal_Width, Petal_Length) %>%
  collect %>%
  ggplot(aes(Petal_Length, Petal_Width)) +
    geom_point(data = model$centers, aes(Petal_Width, Petal_Length), size = 60, alpha = 0.1) +
    geom_point(aes(Petal_Width, Petal_Length), size = 2, alpha = 0.5)

```

## Linear Regression in R

```{r}
data <- iris %>%
  select(Petal.Width, Petal.Length)

model <- lm(Petal.Length ~ Petal.Width, data = iris)

iris %>%
  select(Petal.Width, Petal.Length) %>%
  ggplot(aes(Petal.Length, Petal.Width)) +
    geom_point(data = iris, aes(Petal.Width, Petal.Length), size = 2, alpha = 0.5) +
    geom_abline(aes(slope = coef(model)[["Petal.Width"]],
                    intercept = coef(model)[["(Intercept)"]],
                    color = "red"))
```

## Linear Regression in RSpark

```{r}
model <- tbl(db, "iris") %>%
  select(Petal_Width, Petal_Length) %>%
  ml_linear_regression(response = "Petal_Length", features = c("Petal_Width"))

iris %>%
  select(Petal.Width, Petal.Length) %>%
  ggplot(aes(Petal.Length, Petal.Width)) +
    geom_point(data = iris, aes(Petal.Width, Petal.Length), size = 2, alpha = 0.5) +
    geom_abline(aes(slope = coef(model)[["Petal_Width"]],
                    intercept = coef(model)[["(Intercept)"]],
                    color = "red"))
```

## Partitioning in R

```{r}
ratio <- 0.75
trainingSize <- floor(ratio * nrow(iris))
indices <- sample(seq_len(nrow(iris)), size = trainingSize)

training <- iris[ indices, ]
test     <- iris[-indices, ]

fit <- lm(Petal.Length ~ Petal.Width, data = iris)
predict(fit, newdata = test)
```

## Partitioning in RSpark

```{r}
partitions <- tbl(db, "iris") %>%
  partition(training = 0.75, test = 0.25)

fit <- partitions$training %>%
  ml_linear_regression(response = "Petal_Length", features = c("Petal_Width"))

predict(fit, partitions$test)
```


## Principal Components Analysis in R

```{r}
model <- iris %>%
  select(-Species) %>%
  prcomp()
print(model)

# calculate explained variance
model$sdev^2 / sum(model$sdev^2)
```

## Principal Components Analysis in RSpark

```{r}
model <- tbl(db, "iris") %>%
  select(-Species) %>%
  ml_pca()
print(model)
```

## Random Forests with R

```{r}
library(randomForest)
rForest <- randomForest(
  Sepal.Length ~ Petal.Length + Petal.Width,
  ntree = 20L,
  nodesize = 20L,
  data = iris
)
rPredict <- predict(rForest, iris)
head(rPredict)
```

## Random Forests with RSpark

```{r}
mForest <- iris_tbl %>%
  ml_random_forest(
    response = "Sepal_Length",
    features = c("Petal_Length", "Petal_Width"),
    max.bins = 32L,
    max.depth = 5L,
    num.trees = 20L
  )
mPredict <- predict(mForest, iris_tbl)
head(mPredict)
```

```{r}
ggplot(data.frame(x = rPredict, y = mPredict)) +
  geom_point(aes(x, y)) +
  geom_abline(col = "red") +
  labs(
    x = "R-predicted Sepal Length",
    y = "RSpark-predicted Sepal Length",
    title = "Random Forest Regression â€” Comparing R and RSpark"
  )
```

## Cleanup

```{r}
spark_disconnect(sc)
```
